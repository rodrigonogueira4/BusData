name: "BUS_RIO"
input: "data"
input_dim: 1
input_dim: 3
input_dim: 1
input_dim: 20
layers {
  name: "conv1-1"
  type: CONVOLUTION
  bottom: "data"
  top: "conv1-1"
  convolution_param {
    num_output: 64
    pad_h: 0
    pad_w: 1
    kernel_h: 1
	kernel_w: 3
  }
}
layers {
  name: "relu1-1"
  type: RELU
  bottom: "conv1-1"
  top: "conv1-1"
}
layers {
  name: "conv1-2"
  type: CONVOLUTION
  bottom: "conv1-1"
  top: "conv1-2"
  convolution_param {
    num_output: 64
    pad_h: 0
    pad_w: 1
    kernel_h: 1
	kernel_w: 3
  }
}
layers {
  name: "relu1-2"
  type: RELU
  bottom: "conv1-2"
  top: "conv1-2"
}
layers {
  name: "conv1-3"
  type: CONVOLUTION
  bottom: "conv1-2"
  top: "conv1-3"
  convolution_param {
    num_output: 64
    pad_h: 0
    pad_w: 1
    kernel_h: 1
	kernel_w: 3
  }
}
layers {
  name: "relu1-3"
  type: RELU
  bottom: "conv1-3"
  top: "conv1-3"
}
layers {
  name: "pool1"
  type: POOLING
  bottom: "conv1-3"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_h: 1
	kernel_w: 2
    stride_h: 1
	stride_w: 2
  }
}
layers {
  name: "conv2-1"
  type: CONVOLUTION
  bottom: "pool1"
  top: "conv2-1"
  convolution_param {
    num_output: 128
    pad_h: 0
    pad_w: 1
    kernel_h: 1
	kernel_w: 3
  }
}
layers {
  name: "relu2-1"
  type: RELU
  bottom: "conv2-1"
  top: "conv2-1"
}
layers {
  name: "conv2-2"
  type: CONVOLUTION
  bottom: "conv2-1"
  top: "conv2-2"
  convolution_param {
    num_output: 128
    pad_h: 0
    pad_w: 1
    kernel_h: 1
	  kernel_w: 3
  }
}
layers {
  name: "relu2-2"
  type: RELU
  bottom: "conv2-2"
  top: "conv2-2"
}
layers {
  name: "conv2-3"
  type: CONVOLUTION
  bottom: "conv2-2"
  top: "conv2-3"
  convolution_param {
    num_output: 128
    pad_h: 0
    pad_w: 1
    kernel_h: 1
	  kernel_w: 3
  }
}
layers {
  name: "relu2-3"
  type: RELU
  bottom: "conv2-3"
  top: "conv2-3"
}
layers {
  name: "pool2"
  type: POOLING
  bottom: "conv2-3"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_h: 1
	kernel_w: 2
    stride_h: 1
	stride_w: 2
  }
}
layers {
  name: "fc3"
  type: INNER_PRODUCT
  bottom: "pool2"
  top: "fc3"
  inner_product_param {
    num_output: 2000
  }
}
layers {
  name: "relu3"
  type: RELU
  bottom: "fc3"
  top: "fc3"
}
layers {
  name: "drop3"
  type: DROPOUT
  bottom: "fc3"
  top: "fc3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  name: "fc4"
  type: INNER_PRODUCT
  bottom: "fc3"
  top: "fc4"
  inner_product_param {
    num_output: 2000
  }
}
layers {
  name: "relu4"
  type: RELU
  bottom: "fc4"
  top: "fc4"
}
layers {
  name: "drop4"
  type: DROPOUT
  bottom: "fc4"
  top: "fc4"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc4"
  top: "fc5"
  name: "fc5"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 487
  }
}
layers {
  name: "accuracy-top1"
  type: ACCURACY
  bottom: "fc5"
  bottom: "label"
  top: "accuracy-top1"
  include: { phase: TEST }
}
layers {
  name: "accuracy-top5"
  type: ACCURACY
  bottom: "fc5"
  bottom: "label"
  top: "accuracy-top5"
  accuracy_param {
    top_k: 5
  }
  include: { phase: TEST }
}
layers {
  name: "prob"
  type: SOFTMAX
  bottom: "fc5"
  top: "prob"
}
